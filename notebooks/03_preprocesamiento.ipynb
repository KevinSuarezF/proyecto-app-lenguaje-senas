{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "878d4b73",
   "metadata": {},
   "source": [
    "# Proyecto: Reconocimiento de Lenguaje de Señas Americano (ASL)\n",
    "\n",
    "## Notebook 03: Preprocesamiento de Datos\n",
    "\n",
    "**Objetivo:** Preparar los datos de manera óptima para el entrenamiento de modelos profundos, incluyendo estrategias avanzadas de aumento de datos que simulen condiciones de webcam real.\n",
    "\n",
    "**Contenido:**\n",
    "1. Normalización y estandarización\n",
    "2. Data Augmentation robusto (rotación, zoom, brillo, contraste)\n",
    "3. Técnicas de balanceo de clases\n",
    "4. Generación de conjuntos de validación\n",
    "5. Preprocesamiento específico para Transfer Learning\n",
    "6. Guardado de datasets procesados\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f1ceb",
   "metadata": {},
   "source": [
    "## 0. Importaciones y Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9247fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Configuración\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb52670",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar entorno\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "    BASE_DIR = '/content/sign_language_project'\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "\n",
    "# Rutas\n",
    "DATA_RAW = os.path.join(BASE_DIR, 'data', 'raw')\n",
    "DATA_PROCESSED = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "FIGURES_DIR = os.path.join(BASE_DIR, 'results', 'figures')\n",
    "\n",
    "# Cargar datos\n",
    "train_df = pd.read_csv(os.path.join(DATA_RAW, 'sign_mnist_train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DATA_RAW, 'sign_mnist_test.csv'))\n",
    "\n",
    "# Separar features y labels\n",
    "X_train_raw = train_df.drop('label', axis=1).values\n",
    "y_train_raw = train_df['label'].values\n",
    "X_test_raw = test_df.drop('label', axis=1).values\n",
    "y_test_raw = test_df['label'].values\n",
    "\n",
    "print(f\"Datos de entrenamiento: {X_train_raw.shape}\")\n",
    "print(f\"Datos de prueba: {X_test_raw.shape}\")\n",
    "\n",
    "# Mapeo de etiquetas\n",
    "label_to_letter = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I',\n",
    "    9: 'K', 10: 'L', 11: 'M', 12: 'N', 13: 'O', 14: 'P', 15: 'Q', 16: 'R',\n",
    "    17: 'S', 18: 'T', 19: 'U', 20: 'V', 21: 'W', 22: 'X', 23: 'Y'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217293e2",
   "metadata": {},
   "source": [
    "## 2. Normalización de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización [0, 1] - estándar para imágenes\n",
    "X_train_norm = X_train_raw / 255.0\n",
    "X_test_norm = X_test_raw / 255.0\n",
    "\n",
    "# Reshape a formato de imagen (28, 28, 1)\n",
    "X_train = X_train_norm.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test_norm.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# One-Hot Encoding de etiquetas\n",
    "y_train = to_categorical(y_train_raw, num_classes=24)\n",
    "y_test = to_categorical(y_test_raw, num_classes=24)\n",
    "\n",
    "print(f\"X_train normalizado: {X_train.shape}, rango: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n",
    "print(f\"y_train one-hot: {y_train.shape}\")\n",
    "print(f\"\\nDatos listos para entrenamiento de CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41892cd0",
   "metadata": {},
   "source": [
    "## 3. Creación de Conjunto de Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7029221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir training en train y validation (80-20)\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_train_raw  # Mantener proporción de clases\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train_split.shape[0]:,} muestras\")\n",
    "print(f\"Validation set: {X_val.shape[0]:,} muestras\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} muestras\")\n",
    "print(f\"\\nProporción: {X_train_split.shape[0]/(X_train_split.shape[0]+X_val.shape[0])*100:.1f}% - {X_val.shape[0]/(X_train_split.shape[0]+X_val.shape[0])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dffdff",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation Avanzado (Crítico para Webcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b00d054",
   "metadata": {},
   "source": [
    "### 4.1 Configuración de ImageDataGenerator con Augmentación Robusta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32131f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURACIÓN CLAVE: Simular condiciones de webcam real\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=25,              # Rotación hasta ±25° (webcam no está siempre nivelada)\n",
    "    zoom_range=0.25,                # Zoom de ±25% (distancia variable a cámara)\n",
    "    width_shift_range=0.2,          # Desplazamiento horizontal\n",
    "    height_shift_range=0.2,         # Desplazamiento vertical\n",
    "    shear_range=0.15,               # Cizallamiento (ángulo de cámara)\n",
    "    brightness_range=[0.5, 1.5],    # CRÍTICO: Variación de brillo (diferentes iluminaciones)\n",
    "    channel_shift_range=30,         # Cambio de intensidad de canales\n",
    "    fill_mode='nearest',            # Rellenar con píxeles cercanos\n",
    "    horizontal_flip=False,          # NO voltear (cambiaría el significado de la seña)\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "# Validación y test SIN augmentación\n",
    "val_test_datagen = ImageDataGenerator()\n",
    "\n",
    "# Fit en datos de entrenamiento\n",
    "train_datagen.fit(X_train_split)\n",
    "val_test_datagen.fit(X_val)\n",
    "\n",
    "print(\"Data augmentation configurado exitosamente\")\n",
    "print(\"\\nTransformaciones aplicadas:\")\n",
    "print(\"  - Rotación aleatoria: ±25°\")\n",
    "print(\"  - Zoom aleatorio: ±25%\")\n",
    "print(\"  - Desplazamientos: ±20%\")\n",
    "print(\"  - Brillo: 50% a 150% (CLAVE para webcam)\")\n",
    "print(\"  - Cizallamiento: ±15°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08001d8b",
   "metadata": {},
   "source": [
    "### 4.2 Visualización de Augmentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7536ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar efecto del data augmentation\n",
    "fig, axes = plt.subplots(4, 8, figsize=(20, 10))\n",
    "\n",
    "# Seleccionar 4 imágenes aleatorias\n",
    "for row in range(4):\n",
    "    idx = np.random.randint(0, len(X_train_split))\n",
    "    sample = X_train_split[idx:idx+1]\n",
    "    label_idx = np.argmax(y_train_split[idx])\n",
    "    letter = label_to_letter[label_idx]\n",
    "    \n",
    "    # Imagen original\n",
    "    axes[row, 0].imshow(sample[0, :, :, 0], cmap='gray')\n",
    "    axes[row, 0].set_title(f'Original: {letter}', fontweight='bold', fontsize=11)\n",
    "    axes[row, 0].axis('off')\n",
    "    axes[row, 0].set_facecolor('lightblue')\n",
    "    \n",
    "    # 7 versiones aumentadas\n",
    "    aug_iter = train_datagen.flow(sample, batch_size=1)\n",
    "    for col in range(1, 8):\n",
    "        aug_img = next(aug_iter)[0, :, :, 0]\n",
    "        axes[row, col].imshow(aug_img, cmap='gray')\n",
    "        axes[row, col].set_title(f'Aug {col}', fontsize=10)\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Ejemplos de Data Augmentation Aplicado', fontsize=18, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '03_data_augmentation_examples.png'), dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEl augmentation simula:\")\n",
    "print(\"  - Diferentes ángulos de cámara\")\n",
    "print(\"  - Variaciones de distancia a la cámara\")\n",
    "print(\"  - Condiciones de iluminación variables (oficina, casa, exterior)\")\n",
    "print(\"  - Posición variable de la mano en el frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f018c5",
   "metadata": {},
   "source": [
    "### 4.3 Augmentación Adicional Personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b120e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_advanced_augmentation(image, intensity=0.3):\n",
    "    \"\"\"\n",
    "    Aplica transformaciones adicionales no disponibles en ImageDataGenerator.\n",
    "    Especialmente útil para simular condiciones de webcam real.\n",
    "    \"\"\"\n",
    "    img = image.copy().reshape(28, 28)\n",
    "    \n",
    "    # Aplicar transformaciones aleatorias\n",
    "    if np.random.random() < intensity:\n",
    "        # 1. Ruido gaussiano (sensor de cámara)\n",
    "        noise = np.random.normal(0, 0.05, img.shape)\n",
    "        img = np.clip(img + noise, 0, 1)\n",
    "    \n",
    "    if np.random.random() < intensity:\n",
    "        # 2. Blur (desenfoque de movimiento)\n",
    "        kernel_size = np.random.choice([3, 5])\n",
    "        img = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "    \n",
    "    if np.random.random() < intensity:\n",
    "        # 3. Ajuste de contraste\n",
    "        factor = np.random.uniform(0.7, 1.3)\n",
    "        img = np.clip((img - 0.5) * factor + 0.5, 0, 1)\n",
    "    \n",
    "    if np.random.random() < intensity:\n",
    "        # 4. Ajuste de gamma (simular diferentes exposiciones)\n",
    "        gamma = np.random.uniform(0.7, 1.3)\n",
    "        img = np.power(img, gamma)\n",
    "    \n",
    "    return img.reshape(28, 28, 1)\n",
    "\n",
    "# Demostración\n",
    "fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
    "\n",
    "for i in range(2):\n",
    "    idx = np.random.randint(0, len(X_train_split))\n",
    "    original = X_train_split[idx]\n",
    "    \n",
    "    axes[i, 0].imshow(original[:, :, 0], cmap='gray')\n",
    "    axes[i, 0].set_title('Original', fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    for j in range(1, 6):\n",
    "        augmented = apply_advanced_augmentation(original, intensity=0.5)\n",
    "        axes[i, j].imshow(augmented[:, :, 0], cmap='gray')\n",
    "        axes[i, j].set_title(f'Aug {j}')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.suptitle('Augmentación Avanzada Personalizada\\n(Ruido, Blur, Contraste, Gamma)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '03_advanced_augmentation.png'), dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24c4e9b",
   "metadata": {},
   "source": [
    "## 5. Cálculo de Pesos de Clase (Class Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular pesos de clase para manejar cualquier desbalance\n",
    "class_weights_array = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train_raw),\n",
    "    y=y_train_raw\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(16, 6))\n",
    "letters = [label_to_letter[i] for i in range(24)]\n",
    "plt.bar(letters, class_weights_array, color='teal', alpha=0.7, edgecolor='black')\n",
    "plt.axhline(1.0, color='red', linestyle='--', linewidth=2, label='Peso = 1.0')\n",
    "plt.title('Pesos de Clase para Balanceo', fontsize=15, fontweight='bold')\n",
    "plt.xlabel('Letra', fontsize=12)\n",
    "plt.ylabel('Peso', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '03_class_weights.png'), dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Pesos de clase calculados:\")\n",
    "for i, weight in class_weights.items():\n",
    "    print(f\"  {label_to_letter[i]}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a580ac",
   "metadata": {},
   "source": [
    "## 6. Preprocesamiento para Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7fdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para modelos preentrenados que esperan imágenes RGB\n",
    "def prepare_for_transfer_learning(X, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Prepara imágenes para modelos pre-entrenados:\n",
    "    1. Convierte grayscale a RGB (3 canales)\n",
    "    2. Redimensiona a tamaño requerido (e.g., 224x224)\n",
    "    \"\"\"\n",
    "    # Convertir a RGB repitiendo el canal\n",
    "    X_rgb = np.repeat(X, 3, axis=-1)\n",
    "    \n",
    "    # Redimensionar si es necesario\n",
    "    if X.shape[1:3] != target_size:\n",
    "        X_resized = np.array([\n",
    "            cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "            for img in X_rgb\n",
    "        ])\n",
    "        return X_resized\n",
    "    \n",
    "    return X_rgb\n",
    "\n",
    "# Preparar versiones para diferentes modelos\n",
    "print(\"Preparando datos para Transfer Learning...\")\n",
    "\n",
    "# Para EfficientNet, ResNet, VGG, etc. (224x224)\n",
    "X_train_tl_224 = prepare_for_transfer_learning(X_train_split, target_size=(224, 224))\n",
    "X_val_tl_224 = prepare_for_transfer_learning(X_val, target_size=(224, 224))\n",
    "X_test_tl_224 = prepare_for_transfer_learning(X_test, target_size=(224, 224))\n",
    "\n",
    "print(f\"\\nDatos para Transfer Learning (224x224):\")\n",
    "print(f\"  Train: {X_train_tl_224.shape}\")\n",
    "print(f\"  Val: {X_val_tl_224.shape}\")\n",
    "print(f\"  Test: {X_test_tl_224.shape}\")\n",
    "\n",
    "# Visualizar comparación\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "idx = np.random.randint(0, len(X_train_split))\n",
    "\n",
    "# Original 28x28\n",
    "axes[0, 0].imshow(X_train_split[idx, :, :, 0], cmap='gray')\n",
    "axes[0, 0].set_title('Original 28x28 (Grayscale)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# RGB 28x28\n",
    "X_rgb_28 = np.repeat(X_train_split[idx:idx+1], 3, axis=-1)\n",
    "axes[0, 1].imshow(X_rgb_28[0])\n",
    "axes[0, 1].set_title('RGB 28x28', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# RGB 224x224\n",
    "axes[0, 2].imshow(X_train_tl_224[idx])\n",
    "axes[0, 2].set_title('RGB 224x224 (Transfer Learning)', fontsize=12, fontweight='bold')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Segunda muestra\n",
    "idx2 = np.random.randint(0, len(X_train_split))\n",
    "\n",
    "axes[1, 0].imshow(X_train_split[idx2, :, :, 0], cmap='gray')\n",
    "axes[1, 0].set_title('Original 28x28 (Grayscale)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "X_rgb_28_2 = np.repeat(X_train_split[idx2:idx2+1], 3, axis=-1)\n",
    "axes[1, 1].imshow(X_rgb_28_2[0])\n",
    "axes[1, 1].set_title('RGB 28x28', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(X_train_tl_224[idx2])\n",
    "axes[1, 2].set_title('RGB 224x224 (Transfer Learning)', fontsize=12, fontweight='bold')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.suptitle('Comparación de Formatos de Datos', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '03_formato_transfer_learning.png'), dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363e17b",
   "metadata": {},
   "source": [
    "## 7. Guardado de Datos Procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97be1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar datos procesados en formato .npz (comprimido)\n",
    "print(\"Guardando datos procesados...\")\n",
    "\n",
    "# Dataset estándar (28x28, 1 canal)\n",
    "np.savez_compressed(\n",
    "    os.path.join(DATA_PROCESSED, 'data_standard.npz'),\n",
    "    X_train=X_train_split,\n",
    "    X_val=X_val,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train_split,\n",
    "    y_val=y_val,\n",
    "    y_test=y_test,\n",
    "    y_train_raw=y_train_raw[train_test_split(range(len(y_train_raw)), test_size=0.2, random_state=42, stratify=y_train_raw)[0]],\n",
    "    y_val_raw=y_train_raw[train_test_split(range(len(y_train_raw)), test_size=0.2, random_state=42, stratify=y_train_raw)[1]],\n",
    "    y_test_raw=y_test_raw\n",
    ")\n",
    "\n",
    "print(f\"  - Datos estándar guardados: data_standard.npz\")\n",
    "\n",
    "# Dataset para Transfer Learning (224x224, 3 canales)\n",
    "np.savez_compressed(\n",
    "    os.path.join(DATA_PROCESSED, 'data_transfer_learning_224.npz'),\n",
    "    X_train=X_train_tl_224,\n",
    "    X_val=X_val_tl_224,\n",
    "    X_test=X_test_tl_224,\n",
    "    y_train=y_train_split,\n",
    "    y_val=y_val,\n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "print(f\"  - Datos Transfer Learning guardados: data_transfer_learning_224.npz\")\n",
    "\n",
    "# Guardar metadatos de preprocesamiento\n",
    "preprocessing_metadata = {\n",
    "    'normalization': 'MinMax [0, 1]',\n",
    "    'train_samples': int(X_train_split.shape[0]),\n",
    "    'val_samples': int(X_val.shape[0]),\n",
    "    'test_samples': int(X_test.shape[0]),\n",
    "    'train_val_split_ratio': 0.8,\n",
    "    'augmentation': {\n",
    "        'rotation_range': 25,\n",
    "        'zoom_range': 0.25,\n",
    "        'width_shift_range': 0.2,\n",
    "        'height_shift_range': 0.2,\n",
    "        'brightness_range': [0.5, 1.5],\n",
    "        'shear_range': 0.15\n",
    "    },\n",
    "    'class_weights': {label_to_letter[k]: float(v) for k, v in class_weights.items()},\n",
    "    'label_mapping': label_to_letter\n",
    "}\n",
    "\n",
    "with open(os.path.join(DATA_PROCESSED, 'preprocessing_metadata.json'), 'w') as f:\n",
    "    json.dump(preprocessing_metadata, f, indent=4)\n",
    "\n",
    "print(f\"  - Metadatos guardados: preprocessing_metadata.json\")\n",
    "print(\"\\nTodos los datos procesados guardados exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94672a46",
   "metadata": {},
   "source": [
    "## 8. Resumen del Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0fff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen = f\"\"\"\n",
    "{'='*80}\n",
    "RESUMEN DE PREPROCESAMIENTO\n",
    "{'='*80}\n",
    "\n",
    "1. NORMALIZACIÓN\n",
    "   - Método: MinMax [0, 1]\n",
    "   - Formato: (altura, ancho, canales)\n",
    "   \n",
    "2. DIVISIÓN DE DATOS\n",
    "   - Training: {X_train_split.shape[0]:,} muestras ({X_train_split.shape[0]/(X_train_split.shape[0]+X_val.shape[0])*100:.1f}%)\n",
    "   - Validation: {X_val.shape[0]:,} muestras ({X_val.shape[0]/(X_train_split.shape[0]+X_val.shape[0])*100:.1f}%)\n",
    "   - Test: {X_test.shape[0]:,} muestras\n",
    "   - Estratificado: Sí (mantiene proporción de clases)\n",
    "\n",
    "3. DATA AUGMENTATION\n",
    "   - Rotación: ±25°\n",
    "   - Zoom: ±25%\n",
    "   - Desplazamiento: ±20%\n",
    "   - Brillo: 50% a 150% (crítico para webcam)\n",
    "   - Cizallamiento: ±15°\n",
    "   - Augmentación adicional: Ruido, blur, contraste, gamma\n",
    "\n",
    "4. FORMATOS PREPARADOS\n",
    "   - Estándar CNN: (28, 28, 1) - {X_train_split.nbytes / (1024**2):.1f} MB\n",
    "   - Transfer Learning: (224, 224, 3) - {X_train_tl_224.nbytes / (1024**2):.1f} MB\n",
    "\n",
    "5. BALANCEO\n",
    "   - Pesos de clase calculados\n",
    "   - Rango de pesos: [{min(class_weights_array):.4f}, {max(class_weights_array):.4f}]\n",
    "\n",
    "6. ARCHIVOS GENERADOS\n",
    "   - data_standard.npz\n",
    "   - data_transfer_learning_224.npz\n",
    "   - preprocessing_metadata.json\n",
    "\n",
    "{'='*80}\n",
    "\n",
    "PRÓXIMO PASO:\n",
    "Notebook 04 - Entrenamiento y comparación de múltiples modelos\n",
    "\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(resumen)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
