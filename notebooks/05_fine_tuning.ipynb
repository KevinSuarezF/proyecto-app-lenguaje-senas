{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4563436e",
   "metadata": {},
   "source": [
    "# Notebook 05: Fine-Tuning y Optimización del Mejor Modelo\n",
    "\n",
    "Este notebook realiza fine-tuning del mejor modelo identificado en el notebook anterior.\n",
    "\n",
    "**Objetivos:**\n",
    "1. Cargar el mejor modelo entrenado\n",
    "2. Realizar fine-tuning descongelando capas del modelo base\n",
    "3. Experimentar con diferentes configuraciones de fine-tuning\n",
    "4. Optimizar hiperparámetros (learning rate, batch size, etc.)\n",
    "5. Evaluar mejoras en rendimiento\n",
    "6. Generar modelo final optimizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae4443",
   "metadata": {},
   "source": [
    "## 1. Configuración del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67814a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar si estamos en Colab\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Ejecutando en Google Colab\")\n",
    "    print(\"Verificando GPU disponible...\")\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print(\"Ejecutando en entorno local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fac3b9",
   "metadata": {},
   "source": [
    "### 1.1. Instalación de Dependencias (Solo en Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f989ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    print(\"Instalando dependencias...\")\n",
    "    !pip install -q tensorflow opencv-python scikit-learn seaborn plotly optuna\n",
    "    print(\"Dependencias instaladas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5b47d5",
   "metadata": {},
   "source": [
    "### 1.2. Configuración de Rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ac1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if IN_COLAB:\n",
    "    BASE_DIR = Path('/content/asl_project')\n",
    "    BASE_DIR.mkdir(exist_ok=True)\n",
    "    os.chdir(BASE_DIR)\n",
    "else:\n",
    "    BASE_DIR = Path.cwd().parent\n",
    "    os.chdir(BASE_DIR)\n",
    "\n",
    "print(f\"Directorio base: {BASE_DIR}\")\n",
    "\n",
    "# Crear estructura de directorios\n",
    "DIRS = {\n",
    "    'data_processed': BASE_DIR / 'data' / 'processed',\n",
    "    'models': BASE_DIR / 'models',\n",
    "    'results': BASE_DIR / 'results',\n",
    "    'results_figures': BASE_DIR / 'results' / 'figures',\n",
    "    'results_reports': BASE_DIR / 'results' / 'reports',\n",
    "}\n",
    "\n",
    "for dir_name, dir_path in DIRS.items():\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"✓ {dir_name}: {dir_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c996d45",
   "metadata": {},
   "source": [
    "## 2. Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37788ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# Utilidades\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuración de TensorFlow\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "\n",
    "# Verificar GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"\\n✓ GPU disponible: {len(gpus)} dispositivo(s)\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  - {gpu}\")\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"\\n⚠ No se detectó GPU, usando CPU\")\n",
    "\n",
    "# Semillas\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"\\n✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d3dfb",
   "metadata": {},
   "source": [
    "## 3. Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0efda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos preprocesados\n",
    "print(\"Cargando datos...\")\n",
    "\n",
    "X_train = np.load(DIRS['data_processed'] / 'X_train.npy')\n",
    "X_val = np.load(DIRS['data_processed'] / 'X_val.npy')\n",
    "X_test = np.load(DIRS['data_processed'] / 'X_test.npy')\n",
    "y_train = np.load(DIRS['data_processed'] / 'y_train.npy')\n",
    "y_val = np.load(DIRS['data_processed'] / 'y_val.npy')\n",
    "y_test = np.load(DIRS['data_processed'] / 'y_test.npy')\n",
    "\n",
    "print(f\"\\nForma de los datos:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_val: {X_val.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "\n",
    "# Número de clases\n",
    "NUM_CLASSES = len(np.unique(y_train))\n",
    "print(f\"\\nNúmero de clases: {NUM_CLASSES}\")\n",
    "\n",
    "# Convertir a one-hot\n",
    "y_train_cat = to_categorical(y_train, NUM_CLASSES)\n",
    "y_val_cat = to_categorical(y_val, NUM_CLASSES)\n",
    "y_test_cat = to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "print(\"\\n✓ Datos cargados correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42fa689",
   "metadata": {},
   "source": [
    "## 4. Identificar y Cargar Mejor Modelo\n",
    "\n",
    "Identificamos el mejor modelo del entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d425db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar resultados de comparación\n",
    "comparison_path = DIRS['results_reports'] / 'model_comparison.csv'\n",
    "\n",
    "if comparison_path.exists():\n",
    "    results_df = pd.read_csv(comparison_path)\n",
    "    results_df = results_df.sort_values('Test Accuracy', ascending=False)\n",
    "    \n",
    "    print(\"Resultados de modelos entrenados:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    best_model_name = results_df.iloc[0]['Modelo']\n",
    "    best_accuracy = results_df.iloc[0]['Test Accuracy']\n",
    "    \n",
    "    print(f\"\\nMejor modelo identificado: {best_model_name}\")\n",
    "    print(f\"Accuracy en test: {best_accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"⚠ No se encontraron resultados previos.\")\n",
    "    print(\"Ejecuta el notebook 04_entrenamiento_modelos.ipynb primero.\")\n",
    "    \n",
    "    # Selección manual\n",
    "    best_model_name = 'TL_EfficientNetB0'  # Cambiar según sea necesario\n",
    "    print(f\"\\nUsando modelo: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5591748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el mejor modelo\n",
    "model_path = DIRS['models'] / f\"{best_model_name}.keras\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f\"Error: Modelo no encontrado en {model_path}\")\n",
    "    print(\"Verifica que el modelo haya sido entrenado.\")\n",
    "else:\n",
    "    print(f\"Cargando modelo desde: {model_path}\")\n",
    "    base_model = keras.models.load_model(str(model_path))\n",
    "    \n",
    "    print(\"\\n✓ Modelo cargado correctamente\")\n",
    "    print(f\"\\nResumen del modelo:\")\n",
    "    base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83d6f7",
   "metadata": {},
   "source": [
    "## 5. Estrategia de Fine-Tuning\n",
    "\n",
    "Vamos a realizar fine-tuning descongelando gradualmente capas del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a5f89",
   "metadata": {},
   "source": [
    "### 5.1. Explorar Estructura del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f9011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar capas del modelo\n",
    "print(\"Capas del modelo:\")\n",
    "print(f\"Total de capas: {len(base_model.layers)}\\n\")\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(f\"{i}: {layer.name} - Trainable: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061dfc35",
   "metadata": {},
   "source": [
    "### 5.2. Función de Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(base_model, \n",
    "                   unfreeze_from_layer=None,\n",
    "                   learning_rate=1e-5,\n",
    "                   epochs=20,\n",
    "                   model_name='fine_tuned'):\n",
    "    \"\"\"\n",
    "    Realiza fine-tuning de un modelo preentrenado\n",
    "    \n",
    "    Args:\n",
    "        base_model: Modelo a hacer fine-tuning\n",
    "        unfreeze_from_layer: Índice de capa desde donde descongelar (None = todas)\n",
    "        learning_rate: Tasa de aprendizaje (debe ser baja)\n",
    "        epochs: Número de épocas\n",
    "        model_name: Nombre para guardar el modelo\n",
    "    \n",
    "    Returns:\n",
    "        model: Modelo con fine-tuning\n",
    "        history: Historial de entrenamiento\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fine-Tuning: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Clonar modelo para no modificar el original\n",
    "    model = keras.models.clone_model(base_model)\n",
    "    model.set_weights(base_model.get_weights())\n",
    "    \n",
    "    # Descongelar capas\n",
    "    if unfreeze_from_layer is None:\n",
    "        # Descongelar todas las capas\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "        print(\"Todas las capas descongeladas\")\n",
    "    else:\n",
    "        # Descongelar desde una capa específica\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if i >= unfreeze_from_layer:\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "        print(f\"Descongeladas capas desde {unfreeze_from_layer}\")\n",
    "    \n",
    "    # Contar parámetros\n",
    "    trainable_params = sum(\n",
    "        np.prod(w.shape) for w in model.trainable_weights\n",
    "    )\n",
    "    non_trainable_params = sum(\n",
    "        np.prod(w.shape) for w in model.non_trainable_weights\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nParámetros entrenables: {trainable_params:,}\")\n",
    "    print(f\"Parámetros no entrenables: {non_trainable_params:,}\")\n",
    "    \n",
    "    # Recompilar con learning rate bajo\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nLearning rate: {learning_rate}\")\n",
    "    print(f\"Épocas: {epochs}\")\n",
    "    \n",
    "    # Callbacks\n",
    "    save_path = DIRS['models'] / f\"{model_name}.keras\"\n",
    "    \n",
    "    callbacks_list = [\n",
    "        callbacks.ModelCheckpoint(\n",
    "            str(save_path),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-8,\n",
    "            verbose=1\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    # Data augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.15,\n",
    "        brightness_range=[0.5, 1.5],\n",
    "        shear_range=0.1,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow(\n",
    "        X_train, y_train_cat,\n",
    "        batch_size=128\n",
    "    )\n",
    "    \n",
    "    # Entrenar\n",
    "    start_time = time.time()\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(X_train) // 128,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val_cat),\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\n✓ Fine-tuning completado en {training_time/60:.2f} minutos\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "print(\"✓ Función de fine-tuning definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d8885",
   "metadata": {},
   "source": [
    "## 6. Experimentos de Fine-Tuning\n",
    "\n",
    "Realizamos varios experimentos con diferentes configuraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d2fba",
   "metadata": {},
   "source": [
    "### 6.1. Experimento 1: Fine-Tuning Solo Últimas Capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09855b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descongelar solo las últimas 20 capas\n",
    "total_layers = len(base_model.layers)\n",
    "unfreeze_from = max(0, total_layers - 20)\n",
    "\n",
    "model_ft1, history_ft1 = fine_tune_model(\n",
    "    base_model,\n",
    "    unfreeze_from_layer=unfreeze_from,\n",
    "    learning_rate=1e-5,\n",
    "    epochs=20,\n",
    "    model_name=f'{best_model_name}_ft_last20'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a03b4",
   "metadata": {},
   "source": [
    "### 6.2. Experimento 2: Fine-Tuning Todas las Capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e25d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descongelar todas las capas con learning rate muy bajo\n",
    "model_ft2, history_ft2 = fine_tune_model(\n",
    "    base_model,\n",
    "    unfreeze_from_layer=None,\n",
    "    learning_rate=5e-6,\n",
    "    epochs=20,\n",
    "    model_name=f'{best_model_name}_ft_all'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711701d",
   "metadata": {},
   "source": [
    "### 6.3. Experimento 3: Fine-Tuning con Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning con learning rate adaptativo\n",
    "def lr_schedule(epoch, lr):\n",
    "    \"\"\"\n",
    "    Reduce learning rate gradualmente\n",
    "    \"\"\"\n",
    "    if epoch < 5:\n",
    "        return 1e-5\n",
    "    elif epoch < 10:\n",
    "        return 5e-6\n",
    "    else:\n",
    "        return 1e-6\n",
    "\n",
    "# Crear modelo\n",
    "model_ft3 = keras.models.clone_model(base_model)\n",
    "model_ft3.set_weights(base_model.get_weights())\n",
    "\n",
    "# Descongelar últimas 30 capas\n",
    "unfreeze_from = max(0, total_layers - 30)\n",
    "for i, layer in enumerate(model_ft3.layers):\n",
    "    layer.trainable = i >= unfreeze_from\n",
    "\n",
    "# Compilar\n",
    "model_ft3.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "save_path = DIRS['models'] / f\"{best_model_name}_ft_schedule.keras\"\n",
    "\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        str(save_path),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.LearningRateScheduler(lr_schedule, verbose=1),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=7,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.15,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    X_train, y_train_cat,\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "print(\"\\nExperimento 3: Fine-tuning con learning rate schedule\")\n",
    "history_ft3 = model_ft3.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // 128,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val, y_val_cat),\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e891cb2",
   "metadata": {},
   "source": [
    "## 7. Evaluación de Modelos Fine-Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6aee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar modelo original (baseline)\n",
    "print(\"Evaluando modelo original (baseline)...\")\n",
    "baseline_loss, baseline_acc = base_model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "\n",
    "# Lista de modelos fine-tuned\n",
    "ft_models = [\n",
    "    (f\"{best_model_name}_ft_last20\", \"FT últimas 20 capas\"),\n",
    "    (f\"{best_model_name}_ft_all\", \"FT todas las capas\"),\n",
    "    (f\"{best_model_name}_ft_schedule\", \"FT con LR schedule\")\n",
    "]\n",
    "\n",
    "# Resultados\n",
    "results = [{\n",
    "    'Modelo': 'Baseline (sin FT)',\n",
    "    'Descripción': 'Modelo original',\n",
    "    'Test Loss': baseline_loss,\n",
    "    'Test Accuracy': baseline_acc,\n",
    "    'Mejora': 0.0\n",
    "}]\n",
    "\n",
    "# Evaluar cada modelo fine-tuned\n",
    "for model_name, description in ft_models:\n",
    "    model_path = DIRS['models'] / f\"{model_name}.keras\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"⚠ Modelo no encontrado: {model_name}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nEvaluando {description}...\")\n",
    "    \n",
    "    # Cargar modelo\n",
    "    model = keras.models.load_model(str(model_path))\n",
    "    \n",
    "    # Evaluar\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "    \n",
    "    # Mejora respecto al baseline\n",
    "    improvement = (test_acc - baseline_acc) * 100\n",
    "    \n",
    "    results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Descripción': description,\n",
    "        'Test Loss': test_loss,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Mejora': improvement\n",
    "    })\n",
    "    \n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Mejora: {improvement:+.2f}%\")\n",
    "\n",
    "# Crear DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTADOS DE FINE-TUNING\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Guardar resultados\n",
    "results_df.to_csv(DIRS['results_reports'] / 'fine_tuning_comparison.csv', index=False)\n",
    "print(f\"\\n✓ Resultados guardados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db8813f",
   "metadata": {},
   "source": [
    "## 8. Visualización de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de comparación\n",
    "fig = go.Figure()\n",
    "\n",
    "# Accuracy\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Test Accuracy',\n",
    "    x=results_df['Descripción'],\n",
    "    y=results_df['Test Accuracy'],\n",
    "    marker_color='lightblue',\n",
    "    text=[f\"{acc:.4f}\" for acc in results_df['Test Accuracy']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Comparación: Baseline vs Fine-Tuning',\n",
    "    xaxis_title='Configuración',\n",
    "    yaxis_title='Test Accuracy',\n",
    "    yaxis_range=[0.85, max(results_df['Test Accuracy']) * 1.05],\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Guardar gráfico\n",
    "fig.write_html(str(DIRS['results_figures'] / 'fine_tuning_comparison.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86551b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de mejora porcentual\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=results_df['Descripción'],\n",
    "    y=results_df['Mejora'],\n",
    "    marker_color=['gray'] + ['green' if x > 0 else 'red' for x in results_df['Mejora'][1:]],\n",
    "    text=[f\"{imp:+.2f}%\" for imp in results_df['Mejora']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Mejora Porcentual con Fine-Tuning',\n",
    "    xaxis_title='Configuración',\n",
    "    yaxis_title='Mejora (%)',\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", opacity=0.5)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Guardar\n",
    "fig.write_html(str(DIRS['results_figures'] / 'fine_tuning_improvement.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fbb4c9",
   "metadata": {},
   "source": [
    "## 9. Análisis Detallado del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ac38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar mejor modelo\n",
    "best_ft_model = results_df.iloc[0]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MEJOR MODELO\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Modelo: {best_ft_model['Descripción']}\")\n",
    "print(f\"Test Accuracy: {best_ft_model['Test Accuracy']:.4f}\")\n",
    "print(f\"Mejora: {best_ft_model['Mejora']:+.2f}%\")\n",
    "\n",
    "# Cargar mejor modelo\n",
    "if best_ft_model['Modelo'] == 'Baseline (sin FT)':\n",
    "    final_model = base_model\n",
    "else:\n",
    "    model_path = DIRS['models'] / f\"{best_ft_model['Modelo']}.keras\"\n",
    "    final_model = keras.models.load_model(str(model_path))\n",
    "\n",
    "# Predicciones\n",
    "y_pred = final_model.predict(X_test, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"\\nReporte de Clasificación:\\n\")\n",
    "\n",
    "# Mapeo de labels\n",
    "label_to_letter = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I',\n",
    "    9: 'K', 10: 'L', 11: 'M', 12: 'N', 13: 'O', 14: 'P', 15: 'Q', 16: 'R',\n",
    "    17: 'S', 18: 'T', 19: 'U', 20: 'V', 21: 'W', 22: 'X', 23: 'Y'\n",
    "}\n",
    "\n",
    "target_names = [label_to_letter[i] for i in range(NUM_CLASSES)]\n",
    "\n",
    "report = classification_report(y_test, y_pred_classes, target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "# Guardar reporte\n",
    "with open(DIRS['results_reports'] / 'final_model_report.txt', 'w') as f:\n",
    "    f.write(f\"Mejor Modelo: {best_ft_model['Descripción']}\\n\")\n",
    "    f.write(f\"Test Accuracy: {best_ft_model['Test Accuracy']:.4f}\\n\\n\")\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45746469",
   "metadata": {},
   "source": [
    "## 10. Matriz de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Normalizar\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plotear\n",
    "fig = px.imshow(\n",
    "    cm_normalized,\n",
    "    labels=dict(x=\"Predicción\", y=\"Real\", color=\"Proporción\"),\n",
    "    x=target_names,\n",
    "    y=target_names,\n",
    "    color_continuous_scale='Blues',\n",
    "    title='Matriz de Confusión (Normalizada)'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=800,\n",
    "    xaxis_title='Predicción',\n",
    "    yaxis_title='Real'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Guardar\n",
    "fig.write_html(str(DIRS['results_figures'] / 'confusion_matrix_final.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74426d9",
   "metadata": {},
   "source": [
    "## 11. Guardar Modelo Final\n",
    "\n",
    "Guardamos el mejor modelo con un nombre descriptivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee13906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar como modelo final\n",
    "final_model_name = 'asl_model_final_optimized'\n",
    "final_model_path = DIRS['models'] / f\"{final_model_name}.keras\"\n",
    "\n",
    "final_model.save(str(final_model_path))\n",
    "\n",
    "print(f\"\\n✓ Modelo final guardado en: {final_model_path}\")\n",
    "print(f\"Tamaño del modelo: {final_model_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Guardar metadata\n",
    "metadata = {\n",
    "    'model_name': final_model_name,\n",
    "    'base_architecture': best_model_name,\n",
    "    'fine_tuning_config': best_ft_model['Descripción'],\n",
    "    'test_accuracy': float(best_ft_model['Test Accuracy']),\n",
    "    'improvement': float(best_ft_model['Mejora']),\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'input_shape': [28, 28, 1],\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'target_names': target_names\n",
    "}\n",
    "\n",
    "metadata_path = DIRS['models'] / f\"{final_model_name}_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Metadata guardada en: {metadata_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
